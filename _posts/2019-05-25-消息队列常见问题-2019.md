---
layout:     post
title:      "消息队列常见问题"
subtitle:   " \"keep hungry keep foolish\""
date:       2019-05-25 12:00:00
author:     "Bz"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - 消息队列
    
#     消息队列
    
---
## 问题：保证MQ高可用
    ribbitmq(非分布式)：三种模式，单机模式、普通集群、镜像集群
    1.单机模式：demo级别，生产不考虑
    2.普通集群：多个rabbitmq实例 只有1个实例存消息的(元数据+数据)，其他实例存消息的元数据
    	优点：提升了吞吐量，消费者可以通过任意一个rabbitmq实例 找到元数据、再找到存放数据的结点进行消费
    	缺点：
    	1.通过其他结点找到数据，会造成数据间传递，数据量大影响性能
    	2.存数据的结点宕机、数据就没法消费
    3.镜像集群：多个rabbitmq实例，每个实例存放全量数据(元数据+数据)
    	优点：保证了高可用
    	缺点：数据量大到机器无法容纳，扩展是个问题
    	
    kafka(分布式):
    高可用方案：主从模型，生产者topic的多个副本会存在leader结点，leader再同步给follwer结点
    消费者从leader读取topic，如果leader宕机，follwer会选出新的leader继续为消费者提供topic


## 问题：消息被重复消费
    原因：
    kafka消费者消费的时候重启，offset还未提交，重启后从之前的offset开始
    解决方案：保证幂等性
    根据具体业务场景解决
    1.消费消息的时候 把消费过的消息存在 内存集合set、map等 或缓存redis等中，逻辑判断是否已经消费过这条消息
    2.消费端数据库设置唯一约束


## 问题：消息丢失
    ribbitmq：
    原因：
    	1.生产者：
    		1.遇到网络传输问题、或ribbitmq内部出错导致消息生产失败
    		2.rabbitmq收到消息暂存内存中还未持久化，宕机、重启导致消息丢失
    		3.消费者消费了消息，处理过程中(消息未消费完) 宕机、重启后直接越过这条消息，导致消息丢失
    		解决方案：
    			1.使用事务机制，缺点：同步阻塞
    			2.channel设置撑confirm模式，异步回调处理异常
    	2.ribbitmq：
    		1.消息未开启持久化
    		2.持久化过程中宕机，内存还未写入磁盘的消息丢失
    		解决方案：
    			1.开启rabbitmq的持久化：
    				第1步：创建queue的时候设置持久化
    				第2步：发送消息的时候将消息的deliveryMode设置为2
    			2.与生产者confirm机制配合，只有消息被持久化后才通知生产者ack了
    	3.消费者：
    		1.打开了autoAck机制，它会在消费到数据后自动通知rabbitmq但消息还未被消费完就宕机了
    			导致rabbitmq误以为消息已经被消费
    		解决方案：关闭autoAck，自己写逻辑确认处理完消息后再给rabbitmq发送ack
    
    kafka:
    原因：
    	1.消费者：
    		1.消费到一条消息，消费者自动提交了offset，kafka以为消费完成，但实际上还未消费完成就宕机了
    		解决方案：关闭自动提交offset，改成手动提交offset，但会出现消息重复消费
    	2.kafka：
    		1.leader宕机，数据未来得及同步给follower导致丢失
    		解决方案：
    			1.topic设置replication.factor参数：这个值必须大于1，这个是要求每个partition至少有2个副本
    			2.kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有
    			至少一个follower跟自己保持联系，这样才能确保leader挂了至少还有一个follower
    			3.在producer端设置acks=all，这个是要求每条数据，必须是写入所有replica之后才认为是血成功
    			4.在producer端设置retries=MAX：这个是要求一旦写入失败，就一直重试，卡在这里
    	3.生产者不会丢数据
    		按上述思路设置了acks=all，一定不会丢失，要求的是，leader接收到消息，并且所有的follower都同步了消息，
    		才认为本次写成功，如果没满足条件，将会一直重试
		
		
## 问题：保证消息顺序性
    rabbitmq：
    原因：1个queue，多个consumer
    解决方案：  1.拆分多个queue，每个queue一个consumer
    			2.只一个queue对应一个consumer，consumer内部用内存队列做排队分发给底层不同的worker来处理
    kafka：
    原因：1个toptic，一个partition，一个consumer，内部多线程
    解决方案：一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，N个线程分别消费一个内存queue

## 问题：消息积压，延迟以及过期失效
    原因：1.消费端出问题不消费，或者消费速度很慢，导致消息队列集群磁盘不足，比如数据库挂了
    解决方案：
    	1.先修复consumer问题，确保恢复消费速度，将现有consumer停掉
    	2.新建一个topic，partition是原来的10倍，临时建立原先10倍的queue数量
    	3.写一个临时分发数据的consumer程序，写个程序部署上去消费积压的数据，消费之后不做耗时处理
    	直接均匀轮询写入临时建立好的10倍数量的queue
    	4.接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据
    	5.这种做法相当于临时将queue资源和consumer资源扩大10倍，以10倍的速度来消费
    	6.等消费完积压数据后，回复原先部署架构，重新用原先的consumer机器来消费消息
    原因：2.消息设置了过期时间后就没了，导致大量数据丢失
    解决方案：写临时程序，把丢失的数据查出来，再丢到mq里面去